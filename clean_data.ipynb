{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import spacy\n",
    "import re\n",
    "from typing import Tuple, Any, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_val = pd.read_csv(\"data/val.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "import ast\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "CONTRACTIONS = {\n",
    "    \"n't\": \"not\", \"'ll\": \"will\", \"'re\": \"are\", \"'ve\": \"have\", \"'m\": \"am\", \n",
    "    \"'d\": \"would\", \"'s\": \"is\", \"won't\": \"will not\", \"can't\": \"cannot\"\n",
    "}\n",
    "IRRELEVANT_WORDS = {\"wow\", \"oops\", \"ah\", \"ugh\", \"yay\", \"mhm\", \"`\"}\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def fix_tags_string(x):\n",
    "    if isinstance(x, str):\n",
    "        # Reemplaza múltiples espacios o tabs con una coma\n",
    "        x_clean = re.sub(r\"\\s+\", \",\", x.strip())\n",
    "        # Divide por coma y elimina los elementos vacíos\n",
    "        nums = [int(n) for n in x_clean.strip(\"[]\").split(\",\") if n.strip() != \"\"]\n",
    "        return nums\n",
    "    return x  # Si ya es lista o algo raro, lo deja igual\n",
    "\n",
    "\n",
    "df_train[\"tags\"] = df_train[\"tags\"].apply(fix_tags_string)\n",
    "df_val[\"tags\"] = df_val[\"tags\"].apply(fix_tags_string)\n",
    "df_test[\"tags\"] = df_test[\"tags\"].apply(fix_tags_string)\n",
    "\n",
    "def replace_contractions(text):\n",
    "    for contraction, replacement in CONTRACTIONS.items():\n",
    "        text = re.sub(r\"\\b\" + re.escape(contraction) + r\"\\b\", replacement, text)\n",
    "    return text\n",
    "\n",
    "def process_sentence_and_align_tags(sentence, original_tags):\n",
    "    sentence = replace_contractions(sentence)\n",
    "    sentence = sentence.replace(\"-\", \"\")\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    processed_tokens = []\n",
    "    aligned_tags = []\n",
    "\n",
    "    tag_idx = 0\n",
    "    for token in doc:\n",
    "        if token.is_punct or token.is_space or token.text.lower() in IRRELEVANT_WORDS:\n",
    "            tag_idx += 1  # Skip both token and its tag\n",
    "            continue\n",
    "        if token.is_stop:\n",
    "            tag_idx += 1\n",
    "            continue\n",
    "\n",
    "        processed_tokens.append(token.lemma_)\n",
    "\n",
    "        if tag_idx < len(original_tags):\n",
    "            aligned_tags.append(original_tags[tag_idx])\n",
    "            tag_idx += 1\n",
    "        else:\n",
    "            # If a new token was added from contraction expansion or similar, assign tag 0\n",
    "            aligned_tags.append(0)\n",
    "\n",
    "    return processed_tokens, aligned_tags\n",
    "\n",
    "df_train[[\"tokens\", \"tags\"]] = df_train.apply(\n",
    "    lambda row: pd.Series(process_sentence_and_align_tags(row[\"sentence\"], row[\"tags\"])), axis=1\n",
    ")\n",
    "df_val[[\"tokens\", \"tags\"]] = df_val.apply(\n",
    "    lambda row: pd.Series(process_sentence_and_align_tags(row[\"sentence\"], row[\"tags\"])), axis=1\n",
    ")\n",
    "df_test[[\"tokens\", \"tags\"]] = df_test.apply(\n",
    "    lambda row: pd.Series(process_sentence_and_align_tags(row[\"sentence\"], row[\"tags\"])), axis=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(f\"data/train_token.csv\",index=False)\n",
    "df_test.to_csv(f\"data/test_token.csv\",index=False)\n",
    "df_val.to_csv(f\"data/val_token.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = spacy.load('en_core_web_lg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([520871, 366396, 700279])\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {word: i for i, word in enumerate(glove.vocab.strings)}\n",
    "\n",
    "def word2idx(embedding_dict, tweet):\n",
    "    indices = [embedding_dict[word] for word in tweet if word in embedding_dict]\n",
    "    if not indices:\n",
    "        # Si la secuencia está vacía, devolvemos un índice de padding (0)\n",
    "        indices = [0]  # O cualquier otro valor de padding adecuado\n",
    "    return torch.tensor(indices)\n",
    "\n",
    "# Prueba\n",
    "print(word2idx(word_to_index, [\"hello\", \"Teresa\", \"world\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "class OntoNotesDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.tokens = df[\"tokens\"].tolist()\n",
    "\n",
    "        df[\"tags\"] = df[\"tags\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "        self.tags = [torch.tensor(t, dtype=torch.float32) for t in df[\"tags\"].tolist()]\n",
    "        \n",
    "        self.SA: torch.Tensor = torch.tensor(df[\"SA\"].values, dtype=torch.int)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the length of the dataset.\"\"\"\n",
    "        # TODO: Complete the len function\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[List[str], torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        # TODO: Complete the getitem function\n",
    "        token: str = self.tokens[idx]\n",
    "        tag: torch.Tensor = self.tags[idx]\n",
    "        sa: torch.Tensor = self.SA[idx]\n",
    "        return token, tag, sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \n",
    "    glove = spacy.load('en_core_web_lg')\n",
    "    word_to_index = {word: i for i, word in enumerate(glove.vocab.strings)} \n",
    "\n",
    "    # Ordenar por longitud de la secuencia (descendente)\n",
    "    batch = sorted(batch, key=lambda x: len(x[0]), reverse=True)\n",
    "    texts, labels, sa = zip(*batch)\n",
    "\n",
    "    # Convertir palabras a índices\n",
    "    texts_indx = [word2idx(word_to_index, text) for text in texts if word2idx(word_to_index, text).nelement() > 0]\n",
    "\n",
    "    # Longitudes de cada secuencia\n",
    "    lengths = torch.tensor([len(text) for text in texts_indx], dtype=torch.long)\n",
    "\n",
    "    # Padding a la misma longitud\n",
    "    texts_padded = pad_sequence(texts_indx, batch_first=True, padding_value=0)\n",
    "    tags_padded = pad_sequence(labels, batch_first=True, padding_value=0)\n",
    "\n",
    "    return texts_padded, tags_padded, sa, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                         [0, 0, 0, 0]\n",
       "1                                   [0, 0, 0, 0, 0, 0]\n",
       "2                                      [0, 0, 0, 0, 0]\n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4                             [0, 0, 0, 0, 0, 0, 0, 0]\n",
       "5                                               [0, 0]\n",
       "6    [0, 5, 0, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "7     [0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "8             [0, 0, 0, 9, 10, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "9                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"tags\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "      <th>sentence</th>\n",
       "      <th>SA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[People, start, business, reason]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>People start their own businesses for many rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[chance, fill, sale, tax, record, rarely]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>But a chance to fill out sales - tax records i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[red, tape, bugaboo, small, business]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>Red tape is the bugaboo of small business .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ironically, person, want, run, business, prob...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Ironically , the person who wants to run his o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[business, owner, face, mound, form, regulatio...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Yet every business owner has to face the mound...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[hope, change]</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>There is hope of change .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[week, Sen., Malcolm, Wallop, LRB, R., Wyo, rr...</td>\n",
       "      <td>[0, 5, 0, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Last week , Sen. Malcolm Wallop -LRB- R. , Wyo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[great, federal, regulation, mean, large, enti...</td>\n",
       "      <td>[0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>`` A great many federal regulations are meant ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[lawmaker, busy, try, revive, recently, lapse,...</td>\n",
       "      <td>[0, 0, 0, 9, 10, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Other lawmakers are busy trying to revive the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[optimistic, entrepreneur, await, promise, lan...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Thus , optimistic entrepreneurs await a promis...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0                  [People, start, business, reason]   \n",
       "1          [chance, fill, sale, tax, record, rarely]   \n",
       "2              [red, tape, bugaboo, small, business]   \n",
       "3  [ironically, person, want, run, business, prob...   \n",
       "4  [business, owner, face, mound, form, regulatio...   \n",
       "5                                     [hope, change]   \n",
       "6  [week, Sen., Malcolm, Wallop, LRB, R., Wyo, rr...   \n",
       "7  [great, federal, regulation, mean, large, enti...   \n",
       "8  [lawmaker, busy, try, revive, recently, lapse,...   \n",
       "9  [optimistic, entrepreneur, await, promise, lan...   \n",
       "\n",
       "                                                tags  \\\n",
       "0                                       [0, 0, 0, 0]   \n",
       "1                                 [0, 0, 0, 0, 0, 0]   \n",
       "2                                    [0, 0, 0, 0, 0]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4                           [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "5                                             [0, 0]   \n",
       "6  [0, 5, 0, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7   [0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "8           [0, 0, 0, 9, 10, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "9               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                            sentence  SA  \n",
       "0  People start their own businesses for many rea...   1  \n",
       "1  But a chance to fill out sales - tax records i...   1  \n",
       "2        Red tape is the bugaboo of small business .   0  \n",
       "3  Ironically , the person who wants to run his o...   0  \n",
       "4  Yet every business owner has to face the mound...   1  \n",
       "5                          There is hope of change .   2  \n",
       "6  Last week , Sen. Malcolm Wallop -LRB- R. , Wyo...   1  \n",
       "7  `` A great many federal regulations are meant ...   1  \n",
       "8  Other lawmakers are busy trying to revive the ...   1  \n",
       "9  Thus , optimistic entrepreneurs await a promis...   2  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/train_token.csv\")\n",
    "df_val = pd.read_csv(\"data/val_token.csv\")\n",
    "df_test = pd.read_csv(\"data/test_token.csv\")\n",
    "\n",
    "df_train[\"tokens\"] = df_train[\"tokens\"].apply(ast.literal_eval)\n",
    "df_train[\"tags\"] = df_train[\"tags\"].apply(ast.literal_eval)\n",
    "\n",
    "df_val[\"tokens\"] = df_val[\"tokens\"].apply(ast.literal_eval)\n",
    "df_val[\"tags\"] = df_val[\"tags\"].apply(ast.literal_eval)\n",
    "\n",
    "df_test[\"tokens\"] = df_test[\"tokens\"].apply(ast.literal_eval)\n",
    "df_test[\"tags\"] = df_test[\"tags\"].apply(ast.literal_eval)\n",
    "\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train[\"tokens\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = OntoNotesDataset(df_train)\n",
    "vl_dataset = OntoNotesDataset(df_val)\n",
    "ts_dataset = OntoNotesDataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "      <th>sentence</th>\n",
       "      <th>SA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[People, start, business, reason]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>People start their own businesses for many rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[chance, fill, sale, tax, record, rarely]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>But a chance to fill out sales - tax records i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[red, tape, bugaboo, small, business]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>Red tape is the bugaboo of small business .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ironically, person, want, run, business, prob...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Ironically , the person who wants to run his o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[business, owner, face, mound, form, regulatio...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Yet every business owner has to face the mound...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[hope, change]</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>There is hope of change .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[week, Sen., Malcolm, Wallop, LRB, R., Wyo, rr...</td>\n",
       "      <td>[0, 5, 0, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Last week , Sen. Malcolm Wallop -LRB- R. , Wyo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[great, federal, regulation, mean, large, enti...</td>\n",
       "      <td>[0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>`` A great many federal regulations are meant ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[lawmaker, busy, try, revive, recently, lapse,...</td>\n",
       "      <td>[0, 0, 0, 9, 10, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Other lawmakers are busy trying to revive the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[optimistic, entrepreneur, await, promise, lan...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Thus , optimistic entrepreneurs await a promis...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0                  [People, start, business, reason]   \n",
       "1          [chance, fill, sale, tax, record, rarely]   \n",
       "2              [red, tape, bugaboo, small, business]   \n",
       "3  [ironically, person, want, run, business, prob...   \n",
       "4  [business, owner, face, mound, form, regulatio...   \n",
       "5                                     [hope, change]   \n",
       "6  [week, Sen., Malcolm, Wallop, LRB, R., Wyo, rr...   \n",
       "7  [great, federal, regulation, mean, large, enti...   \n",
       "8  [lawmaker, busy, try, revive, recently, lapse,...   \n",
       "9  [optimistic, entrepreneur, await, promise, lan...   \n",
       "\n",
       "                                                tags  \\\n",
       "0                                       [0, 0, 0, 0]   \n",
       "1                                 [0, 0, 0, 0, 0, 0]   \n",
       "2                                    [0, 0, 0, 0, 0]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4                           [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "5                                             [0, 0]   \n",
       "6  [0, 5, 0, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7   [0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "8           [0, 0, 0, 9, 10, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "9               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                            sentence  SA  \n",
       "0  People start their own businesses for many rea...   1  \n",
       "1  But a chance to fill out sales - tax records i...   1  \n",
       "2        Red tape is the bugaboo of small business .   0  \n",
       "3  Ironically , the person who wants to run his o...   0  \n",
       "4  Yet every business owner has to face the mound...   1  \n",
       "5                          There is hope of change .   2  \n",
       "6  Last week , Sen. Malcolm Wallop -LRB- R. , Wyo...   1  \n",
       "7  `` A great many federal regulations are meant ...   1  \n",
       "8  Other lawmakers are busy trying to revive the ...   1  \n",
       "9  Thus , optimistic entrepreneurs await a promis...   2  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader: DataLoader = DataLoader(tr_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_dataloader: DataLoader = DataLoader(vl_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "test_dataloader: DataLoader = DataLoader(ts_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[299130,  75433, 391439,  ..., 554963, 642912, 563008],\n",
      "        [636492, 592034, 511715,  ...,      0,      0,      0],\n",
      "        [ 23022, 265946, 401241,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [464171,      0,      0,  ...,      0,      0,      0],\n",
      "        [600852,      0,      0,  ...,      0,      0,      0],\n",
      "        [629398,      0,      0,  ...,      0,      0,      0]])\n",
      "(tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32))\n",
      "tensor([[0., 4., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 3., 0.,  ..., 0., 0., 0.],\n",
      "        [7., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[684880, 660328, 642674,  ..., 474234, 592603, 407171],\n",
      "        [462251, 438990, 613208,  ..., 490833,      0,      0],\n",
      "        [454222, 612769, 627185,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [581545,      0,      0,  ...,      0,      0,      0],\n",
      "        [683380,      0,      0,  ...,      0,      0,      0],\n",
      "        [500820,      0,      0,  ...,      0,      0,      0]])\n",
      "(tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32))\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 3., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for inputs, tags, sa, lengths in train_dataloader:\n",
    "    print(inputs)\n",
    "    print(sa)\n",
    "    print(tags)\n",
    "\n",
    "    i += 1\n",
    "    if i == 2:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unrelieved', 'substantive', 'shallowness']\n"
     ]
    }
   ],
   "source": [
    "lista = [684880, 660328, 642674]\n",
    "\n",
    "def idx2word(index_tensor, index_to_word):\n",
    "    return [index_to_word[i] for i in index_tensor]\n",
    "\n",
    "index_to_word = {i: word for word, i in word_to_index.items()}\n",
    "\n",
    "print(idx2word(lista, index_to_word))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
